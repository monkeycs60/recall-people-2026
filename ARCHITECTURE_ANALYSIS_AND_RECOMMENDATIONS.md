# Analyse Architecture & Recommandations - Recall People

> **Mission** : Permettre de se remÃ©morer facilement la vie des gens, les choses et dÃ©tails qu'ils nous ont confiÃ©s, et les Ã©vÃ©nements Ã  venir dans leur vie.

---

## Table des MatiÃ¨res

1. [Ã‰tat Actuel de l'Architecture](#1-Ã©tat-actuel-de-larchitecture)
2. [Limites et Points de Faiblesse](#2-limites-et-points-de-faiblesse)
3. [Analyse des LLM & Providers](#3-analyse-des-llm--providers)
4. [Recommandations d'Architecture](#4-recommandations-darchitecture)
5. [StratÃ©gies de Robustesse](#5-stratÃ©gies-de-robustesse)
6. [Plan d'Action PriorisÃ©](#6-plan-daction-priorisÃ©)

---

## 1. Ã‰tat Actuel de l'Architecture

### Flow de Traitement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Recording  â”‚â”€â”€â”€â–¶â”‚ Transcriptionâ”‚â”€â”€â”€â–¶â”‚ Contact Detectionâ”‚â”€â”€â”€â–¶â”‚  Extraction â”‚
â”‚ (Audio/Text)â”‚    â”‚ (Deepgram/   â”‚    â”‚ (Cerebras       â”‚    â”‚ (xAI Grok)  â”‚
â”‚             â”‚    â”‚  Groq)       â”‚    â”‚  Llama 8B)      â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                     â”‚
                                                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite    â”‚â—€â”€â”€â”€â”‚    Save      â”‚â—€â”€â”€â”€â”‚  User Review    â”‚â—€â”€â”€â”€â”‚  Structured â”‚
â”‚   Local     â”‚    â”‚              â”‚    â”‚  (Validation)   â”‚    â”‚    Output   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Points Forts Actuels

| Aspect | ImplÃ©mentation | Ã‰valuation |
|--------|----------------|------------|
| **Privacy** | Local-first (SQLite), backend stateless | âœ… Excellent |
| **SÃ©curitÃ© prompts** | Wrappers avec tokens alÃ©atoires, sanitization | âœ… Robuste |
| **CatÃ©gories** | 18 types de faits + hot topics + memories | âœ… Complet |
| **Review utilisateur** | Ã‰cran de validation avant sauvegarde | âœ… Critique et prÃ©sent |
| **Multi-provider** | Switching facile STT/LLM | âœ… Flexible |
| **Ã‰valuation** | LLM-as-judge avec sampling | âœ… En place |

### Configuration Actuelle

| Endpoint | Provider | ModÃ¨le | CoÃ»t estimÃ© |
|----------|----------|--------|-------------|
| Transcription | Deepgram / Groq | Nova-3 / Whisper v3 | ~$0.003/min |
| Detection | Cerebras | Llama 3.1 8B | TrÃ¨s faible |
| Extraction | xAI | Grok 4.1 Fast | ~$0.01/req |
| Summary | xAI | Grok 4.1 Fast | ~$0.005/req |

---

## 2. Limites et Points de Faiblesse

### 2.1 DÃ©pendances Critiques au LLM

#### âš ï¸ CatÃ©gorisation des Faits (RISQUE Ã‰LEVÃ‰)

**ProblÃ¨me** : Le LLM doit distinguer entre 18 types de faits + hot topics + memories. Les frontiÃ¨res sont souvent floues.

| Exemple | Classification Attendue | Risque de Confusion |
|---------|------------------------|---------------------|
| "Il fait du tennis tous les dimanches" | `hobby` ou `sport` | Moyen |
| "Son fils commence le foot" | `children` (avec dÃ©tail) | Faible |
| "Il dÃ©mÃ©nage Ã  Lyon en mars" | Hot topic (temporaire) OU `location` (permanent) | **Ã‰levÃ©** |
| "Elle a eu une promotion" | Hot topic OU `work` ? | **Ã‰levÃ©** |
| "On a fait du ski ensemble" | `memory` OU `hobby` ? | **Ã‰levÃ©** |

**Impact** : DonnÃ©es mal classÃ©es = difficiles Ã  retrouver, UX dÃ©gradÃ©e.

#### âš ï¸ Calcul des Dates (RISQUE MOYEN-Ã‰LEVÃ‰)

**ProblÃ¨me** : Le LLM doit convertir "dans 3 semaines", "mardi prochain", "fin janvier" en dates absolues.

```
"Son anniversaire c'est fin janvier"
â†’ Attendu: 25/01/2026 (estimation)
â†’ Risque: 31/01/2026, 30/01/2026, ou hallucination

"Il part en vacances la semaine prochaine"
â†’ Si dit le mercredi 15/01, "semaine prochaine" = 20-26/01
â†’ Risque: LLM interprÃ¨te diffÃ©remment selon le contexte
```

**Impact** : Rappels au mauvais moment = perte de confiance utilisateur.

#### âš ï¸ DÃ©tection de RÃ©solution des Hot Topics (RISQUE Ã‰LEVÃ‰)

**ProblÃ¨me** : DÃ©tecter quand un sujet prÃ©cÃ©demment mentionnÃ© est rÃ©solu ET extraire les dÃ©tails.

```
Note 1: "Marie cherche un nouvel appart"
â†’ Hot topic crÃ©Ã©: "Recherche appartement"

Note 2: "Marie a finalement trouvÃ© un 3 piÃ¨ces Ã  Belleville"
â†’ Attendu: RÃ©soudre le hot topic avec "3 piÃ¨ces Ã  Belleville"
â†’ Risque: CrÃ©er un NOUVEAU hot topic au lieu de rÃ©soudre l'ancien
```

**Impact** : Accumulation de hot topics non rÃ©solus, donnÃ©es incohÃ©rentes.

#### âš ï¸ Hallucinations (RISQUE CRITIQUE)

**ProblÃ¨me** : Le LLM peut inventer des informations non prÃ©sentes dans la transcription.

```
Transcription: "Paul travaille dans la tech"
â†’ Risque d'hallucination: "Paul travaille chez Google en tant que dÃ©veloppeur senior"
```

**Mitigations actuelles** :
- Prompts avec instructions strictes âœ…
- Security wrappers âœ…
- User review âœ…
- Mais: toujours possible si l'utilisateur ne fait pas attention

### 2.2 ProblÃ¨mes de Consistance

#### VariabilitÃ© des Outputs

MÃªme input â†’ outputs diffÃ©rents selon :
- Le modÃ¨le utilisÃ©
- La tempÃ©rature (actuellement non fixÃ©e Ã  0)
- Le contexte prÃ©cÃ©dent
- La charge du provider

#### DÃ©pendance aux Prompts Longs

Le prompt d'extraction fait **485 lignes**. ProblÃ¨mes :
- Difficile Ã  maintenir
- Risque de contradictions internes
- CoÃ»t token Ã©levÃ©
- Performance dÃ©gradÃ©e sur certains modÃ¨les

### 2.3 FragilitÃ©s OpÃ©rationnelles

| ProblÃ¨me | Impact | ProbabilitÃ© |
|----------|--------|-------------|
| Provider down (xAI, Cerebras) | App inutilisable | Moyenne |
| Changement de pricing | CoÃ»ts imprÃ©vus | Ã‰levÃ©e |
| Deprecation de modÃ¨le | Migration forcÃ©e | Certaine |
| Rate limiting | ExpÃ©rience dÃ©gradÃ©e | Moyenne |

---

## 3. Analyse des LLM & Providers

### 3.1 Comparatif Providers pour Extraction StructurÃ©e

| Provider/ModÃ¨le | CoÃ»t/10K extractions | Vitesse (tok/s) | Structured Output | FiabilitÃ© |
|-----------------|---------------------|-----------------|-------------------|-----------|
| **Gemini 2.0 Flash** | ~$1.09 | 120 | Native JSON Schema | â­â­â­â­ |
| **GPT-4o-mini** | ~$2.18 | 85 | 100% avec Structured Outputs API | â­â­â­â­â­ |
| **Mistral Small 3** | ~$1.25 | 150 | Bon | â­â­â­â­ |
| **Groq (Llama 3.3 70B)** | ~$5.42 | 1660 | Via JSON mode | â­â­â­ |
| **Claude 3.5 Haiku** | ~$16.50 | 23 | Bon | â­â­â­â­â­ |
| **xAI Grok (actuel)** | ~$3-5 | ~80 | Bon | â­â­â­â­ |

### 3.2 Recommandations par Use Case

#### Extraction Principale â†’ **GPT-4o-mini** (RecommandÃ©)

**Pourquoi** :
- **100% de conformitÃ© schÃ©ma** avec Structured Outputs API (aucun autre n'offre cette garantie)
- Excellent rapport qualitÃ©/prix
- API stable et mature
- Grande communautÃ©, beaucoup de ressources

**Alternative Ã©conomique** : Gemini 2.0 Flash (2x moins cher, 95%+ fiabilitÃ©)

#### Detection Contact â†’ **Garder Cerebras Llama 3.1 8B** âœ…

**Pourquoi** :
- TÃ¢che simple (identification de nom)
- Ultra rapide et quasi gratuit
- Suffisamment fiable pour cette tÃ¢che

#### Transcription â†’ **Groq Whisper v3 Turbo** (RecommandÃ©)

**Pourquoi** :
- 8x plus rapide que Whisper v3 standard
- QualitÃ© quasi Ã©quivalente
- Meilleur que Deepgram pour le franÃ§ais

### 3.3 Architecture Multi-Provider RecommandÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CONFIGURATION RECOMMANDÃ‰E                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TRANSCRIPTION                                                   â”‚
â”‚  â”œâ”€â”€ Primary: Groq Whisper v3 Turbo (rapide, bon franÃ§ais)      â”‚
â”‚  â””â”€â”€ Fallback: Deepgram Nova-3                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DETECTION CONTACT                                               â”‚
â”‚  â”œâ”€â”€ Primary: Cerebras Llama 3.1 8B (actuel, garder)            â”‚
â”‚  â””â”€â”€ Fallback: GPT-4o-mini                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  EXTRACTION STRUCTURÃ‰E                                           â”‚
â”‚  â”œâ”€â”€ Primary: OpenAI GPT-4o-mini + Structured Outputs           â”‚
â”‚  â””â”€â”€ Fallback: Gemini 2.0 Flash                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SUMMARY / ICE-BREAKERS                                          â”‚
â”‚  â”œâ”€â”€ Primary: GPT-4o-mini (ou garder Grok)                      â”‚
â”‚  â””â”€â”€ Fallback: Claude 3.5 Haiku (meilleure qualitÃ© rÃ©daction)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.4 Estimation CoÃ»ts Mensuels

**HypothÃ¨se** : 1000 utilisateurs actifs, 5 notes/jour/utilisateur

| Composant | Actuel (Grok/Cerebras) | RecommandÃ© (GPT-4o-mini) |
|-----------|------------------------|--------------------------|
| Transcription | ~$150/mois | ~$100/mois (Groq) |
| Detection | ~$5/mois | ~$5/mois |
| Extraction | ~$200/mois | ~$100/mois |
| Summary | ~$50/mois | ~$50/mois |
| **TOTAL** | **~$405/mois** | **~$255/mois** |

---

## 4. Recommandations d'Architecture

### 4.1 Utiliser les Structured Outputs d'OpenAI

**Changement majeur recommandÃ©** : Migrer l'extraction vers GPT-4o-mini avec Structured Outputs.

**Avant (actuel)** :
```typescript
// Prompt de 485 lignes avec instructions JSON
const response = await ai.complete({
  messages: [{ role: 'user', content: longPrompt }],
});
const parsed = JSON.parse(response); // Peut Ã©chouer
```

**AprÃ¨s (recommandÃ©)** :
```typescript
import { zodResponseFormat } from 'openai/helpers/zod';

const ExtractionSchema = z.object({
  noteTitle: z.string().max(30),
  contactInfo: z.object({
    phone: z.string().nullable(),
    email: z.string().email().nullable(),
    birthday: z.object({
      day: z.number().min(1).max(31),
      month: z.number().min(1).max(12),
      year: z.number().nullable(),
    }).nullable(),
  }),
  facts: z.array(z.object({
    factType: z.enum(['work', 'company', 'education', /* ... */]),
    factKey: z.string(),
    factValue: z.string(),
    action: z.enum(['add', 'update']),
  })),
  // ... reste du schÃ©ma
});

const response = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [...],
  response_format: zodResponseFormat(ExtractionSchema, 'extraction'),
});

// Garanti d'Ãªtre valide selon le schÃ©ma
const extraction = response.choices[0].message.parsed;
```

**Avantages** :
- âœ… 100% de conformitÃ© schÃ©ma (vs ~80-90% avec JSON mode)
- âœ… Validation automatique des types
- âœ… Pas de parsing JSON manuel qui peut Ã©chouer
- âœ… Meilleure gestion des enums (factType limitÃ© aux valeurs valides)

### 4.2 Pipeline Multi-Ã‰tapes

**ProblÃ¨me actuel** : Un seul appel LLM fait tout (detection + extraction + catÃ©gorisation).

**Recommandation** : Diviser en Ã©tapes spÃ©cialisÃ©es.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE MULTI-Ã‰TAPES                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  Ã‰TAPE 1: EXTRACTION BRUTE (GPT-4o-mini)                                 â”‚
â”‚  â”œâ”€â”€ Input: Transcription seule                                          â”‚
â”‚  â”œâ”€â”€ Output: Liste de faits bruts sans catÃ©gorisation                    â”‚
â”‚  â””â”€â”€ Prompt: Court, focalisÃ© sur l'extraction                            â”‚
â”‚                                                                           â”‚
â”‚  Ã‰TAPE 2: CATÃ‰GORISATION (GPT-4o-mini ou rÃ¨gles)                         â”‚
â”‚  â”œâ”€â”€ Input: Faits bruts + contexte existant du contact                   â”‚
â”‚  â”œâ”€â”€ Output: Faits catÃ©gorisÃ©s (factType assignÃ©)                        â”‚
â”‚  â””â”€â”€ Prompt: FocalisÃ© sur la classification avec exemples                â”‚
â”‚                                                                           â”‚
â”‚  Ã‰TAPE 3: DÃ‰TECTION HOT TOPICS (GPT-4o-mini)                             â”‚
â”‚  â”œâ”€â”€ Input: Faits + hot topics existants                                 â”‚
â”‚  â”œâ”€â”€ Output: Nouveaux hot topics + rÃ©solutions                           â”‚
â”‚  â””â”€â”€ Prompt: FocalisÃ© sur temporel vs permanent                          â”‚
â”‚                                                                           â”‚
â”‚  Ã‰TAPE 4: VALIDATION (RÃ¨gles + LLM)                                      â”‚
â”‚  â”œâ”€â”€ VÃ©rification croisÃ©e avec source                                    â”‚
â”‚  â”œâ”€â”€ DÃ©tection d'hallucinations potentielles                             â”‚
â”‚  â””â”€â”€ Score de confiance par champ                                        â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- Chaque Ã©tape a un prompt court et focalisÃ©
- Plus facile Ã  dÃ©bugger et amÃ©liorer
- PossibilitÃ© d'utiliser des modÃ¨les diffÃ©rents par Ã©tape
- Recherche montre : **+9% de qualitÃ© Ã  1/25 du coÃ»t** avec pipelines multi-Ã©tapes

**InconvÃ©nients** :
- Latence additionnelle (mais parallÃ©lisable en partie)
- ComplexitÃ© de code accrue

### 4.3 Validation et DÃ©tection d'Hallucinations

#### MÃ©thode ChatExtract (90% de prÃ©cision)

Ajouter une Ã©tape de **vÃ©rification par questions** :

```typescript
// AprÃ¨s extraction
const verificationPrompt = `
BasÃ© sur cette transcription:
"${transcription}"

Le systÃ¨me a extrait les faits suivants:
${JSON.stringify(extractedFacts)}

Pour chaque fait, rÃ©ponds:
1. Ce fait est-il EXPLICITEMENT mentionnÃ© dans la transcription? (oui/non)
2. Si non, quelle partie est une infÃ©rence ou hallucination?

Format JSON:
{
  "verifications": [
    { "factIndex": 0, "isExplicit": true/false, "issue": "..." }
  ]
}
`;
```

#### Scoring de Confiance

Assigner un score de confiance Ã  chaque extraction :

```typescript
interface ExtractedFact {
  factType: FactType;
  factValue: string;
  confidence: 'high' | 'medium' | 'low';
  confidenceReason?: string; // "Explicitly stated" | "Inferred from context"
}
```

Afficher le niveau de confiance dans l'UI de review pour alerter l'utilisateur.

### 4.4 Few-Shot Examples Dynamiques

**ProblÃ¨me** : Le prompt actuel a des exemples statiques. Ils ne couvrent pas tous les edge cases.

**Solution** : Banque d'exemples avec sÃ©lection dynamique.

```typescript
// Banque d'exemples par catÃ©gorie
const exampleBank = {
  dateCalculation: [
    { input: "dans 3 semaines", context: "dit le 15/01", output: "05/02" },
    { input: "mardi prochain", context: "dit le mercredi", output: "mardi suivant" },
    // ...
  ],
  hotTopicVsFact: [
    { input: "Il dÃ©mÃ©nage Ã  Lyon", output: "hot_topic", reason: "En cours" },
    { input: "Il habite Ã  Lyon", output: "fact:location", reason: "Ã‰tat actuel" },
    // ...
  ],
  // ...
};

// SÃ©lectionner les exemples pertinents basÃ© sur le contenu
function selectExamples(transcription: string): Example[] {
  const examples = [];
  if (containsDateExpression(transcription)) {
    examples.push(...exampleBank.dateCalculation.slice(0, 2));
  }
  if (containsTransitionVerbs(transcription)) {
    examples.push(...exampleBank.hotTopicVsFact.slice(0, 2));
  }
  return examples.slice(0, 5); // Max 5 exemples
}
```

---

## 5. StratÃ©gies de Robustesse

### 5.1 Fallback Automatique

```typescript
interface ProviderConfig {
  primary: Provider;
  fallback: Provider;
  timeout: number;
  maxRetries: number;
}

async function extractWithFallback(
  transcription: string,
  config: ProviderConfig
): Promise<Extraction> {
  try {
    return await withTimeout(
      extract(transcription, config.primary),
      config.timeout
    );
  } catch (error) {
    console.warn(`Primary failed: ${error.message}, trying fallback`);
    return await extract(transcription, config.fallback);
  }
}
```

### 5.2 Retry avec Feedback

```typescript
async function extractWithRetry(
  transcription: string,
  maxRetries: number = 3
): Promise<Extraction> {
  let lastError: Error | null = null;

  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const result = await extract(transcription);
      const validation = await validate(result, transcription);

      if (validation.isValid) {
        return result;
      }

      // Retry avec le feedback de validation
      transcription = `${transcription}\n\nNote: Previous extraction had issues: ${validation.errors.join(', ')}`;

    } catch (error) {
      lastError = error;
      await sleep(Math.pow(2, attempt) * 1000); // Exponential backoff
    }
  }

  throw lastError || new Error('Max retries exceeded');
}
```

### 5.3 Temperature = 0

**Changement simple mais important** : Forcer `temperature: 0` pour toutes les extractions.

```typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o-mini',
  messages: [...],
  temperature: 0, // CRITIQUE: Output dÃ©terministe
  response_format: zodResponseFormat(ExtractionSchema, 'extraction'),
});
```

### 5.4 Circuit Breaker pour Providers

```typescript
class ProviderCircuitBreaker {
  private failures: number = 0;
  private lastFailure: Date | null = null;
  private readonly threshold = 5;
  private readonly resetTime = 60000; // 1 minute

  async call<T>(fn: () => Promise<T>): Promise<T> {
    if (this.isOpen()) {
      throw new Error('Circuit breaker is open');
    }

    try {
      const result = await fn();
      this.reset();
      return result;
    } catch (error) {
      this.recordFailure();
      throw error;
    }
  }

  private isOpen(): boolean {
    if (this.failures >= this.threshold) {
      if (Date.now() - this.lastFailure!.getTime() < this.resetTime) {
        return true;
      }
      this.reset();
    }
    return false;
  }
}
```

### 5.5 Monitoring et Alertes

MÃ©triques Ã  tracker :

| MÃ©trique | Seuil d'alerte | Action |
|----------|----------------|--------|
| Taux d'Ã©chec extraction | > 5% | Switch provider |
| Latence P95 | > 10s | VÃ©rifier provider |
| CoÃ»t journalier | > budget Ã— 1.5 | Alerter + throttle |
| Score qualitÃ© moyen | < 7/10 | Review prompts |
| Hallucinations dÃ©tectÃ©es | > 2% | Review + fix |

---

## 6. Plan d'Action PriorisÃ©

### Phase 1 : Quick Wins (1-2 semaines)

| Action | Impact | Effort | PrioritÃ© |
|--------|--------|--------|----------|
| âœ… Ajouter `temperature: 0` partout | Ã‰levÃ© | Faible | **P0** |
| âœ… Migrer vers GPT-4o-mini + Structured Outputs | Ã‰levÃ© | Moyen | **P0** |
| âœ… ImplÃ©menter fallback provider | Moyen | Faible | **P1** |
| âœ… Ajouter mÃ©triques de monitoring | Moyen | Faible | **P1** |

### Phase 2 : AmÃ©liorations Structurelles (2-4 semaines)

| Action | Impact | Effort | PrioritÃ© |
|--------|--------|--------|----------|
| ğŸ”„ Pipeline multi-Ã©tapes | Ã‰levÃ© | Ã‰levÃ© | **P1** |
| ğŸ”„ Validation ChatExtract | Ã‰levÃ© | Moyen | **P1** |
| ğŸ”„ Scoring de confiance | Moyen | Moyen | **P2** |
| ğŸ”„ Few-shot dynamiques | Moyen | Moyen | **P2** |

### Phase 3 : Optimisation Continue (Ongoing)

| Action | Impact | Effort | PrioritÃ© |
|--------|--------|--------|----------|
| ğŸ“Š A/B testing prompts | Moyen | Moyen | **P2** |
| ğŸ“Š Analyse erreurs utilisateurs | Ã‰levÃ© | Faible | **P1** |
| ğŸ“Š Fine-tuning si volume suffisant | Ã‰levÃ© | Ã‰levÃ© | **P3** |
| ğŸ“Š Ã‰valuation continue qualitÃ© | Moyen | Faible | **P1** |

---

## Annexe A : Checklist Migration GPT-4o-mini

```markdown
- [ ] CrÃ©er compte OpenAI API (si pas dÃ©jÃ  fait)
- [ ] DÃ©finir schÃ©mas Zod pour toutes les extractions
- [ ] ImplÃ©menter client OpenAI avec Structured Outputs
- [ ] Adapter les prompts (plus courts, focalisÃ©s)
- [ ] Tester sur Ã©chantillon de notes existantes
- [ ] Comparer qualitÃ© vs solution actuelle
- [ ] ImplÃ©menter fallback vers Gemini
- [ ] DÃ©ployer en A/B test (10% trafic)
- [ ] Monitor mÃ©triques pendant 1 semaine
- [ ] Rollout complet si mÃ©triques OK
```

## Annexe B : SchÃ©ma Zod RecommandÃ©

```typescript
import { z } from 'zod';

const FactTypeEnum = z.enum([
  'work', 'company', 'education', 'location', 'origin',
  'partner', 'children', 'hobby', 'sport', 'language',
  'pet', 'how_met', 'where_met', 'shared_ref', 'trait',
  'gift_idea', 'gift_given', 'relationship', 'other'
]);

const ExtractedFactSchema = z.object({
  factType: FactTypeEnum,
  factKey: z.string().describe('Identificateur court du fait'),
  factValue: z.string().describe('Valeur extraite de la transcription'),
  title: z.string().nullable().describe('Titre pour type "other" uniquement'),
  action: z.enum(['add', 'update']),
  previousValue: z.string().nullable(),
  confidence: z.enum(['high', 'medium', 'low']),
});

const HotTopicSchema = z.object({
  title: z.string().max(50),
  context: z.string().describe('DÃ©tails et contexte'),
  suggestedDate: z.string().nullable().describe('Format DD/MM/YYYY'),
  isNew: z.boolean().describe('true si nouveau, false si rÃ©solution'),
  resolvesTopicId: z.string().nullable().describe('ID du topic rÃ©solu'),
  resolution: z.string().nullable().describe('DÃ©tails de la rÃ©solution'),
});

const MemorySchema = z.object({
  description: z.string(),
  eventDate: z.string().nullable(),
  isShared: z.boolean().describe('true si vÃ©cu ensemble'),
});

export const ExtractionSchema = z.object({
  noteTitle: z.string().max(30).describe('2-4 mots rÃ©sumant la note'),
  contactInfo: z.object({
    phone: z.string().nullable(),
    email: z.string().nullable(),
    birthday: z.object({
      day: z.number().min(1).max(31),
      month: z.number().min(1).max(12),
      year: z.number().nullable(),
    }).nullable(),
  }),
  facts: z.array(ExtractedFactSchema),
  hotTopics: z.array(HotTopicSchema),
  resolvedTopics: z.array(z.object({
    id: z.string(),
    resolution: z.string(),
  })),
  memories: z.array(MemorySchema),
});
```

## Annexe C : Ressources

### Documentation
- [OpenAI Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
- [Gemini JSON Schema](https://ai.google.dev/gemini-api/docs/json-mode)
- [Zod Documentation](https://zod.dev/)

### Papers & Articles
- [ChatExtract: 90% accuracy with verification questions](https://www.nature.com/articles/s41467-024-45914-8)
- [Multi-stage pipelines: 9% better at 1/25th cost](https://www.emergentmind.com/topics/multi-stage-llm-based-classification-pipeline)
- [Hallucination rates 2021-2026](https://masterofcode.com/blog/hallucinations-in-llms-what-you-need-to-know-before-integration)

### Benchmarks
- [Artificial Analysis - Model comparisons](https://artificialanalysis.ai/)
- [LLM Pricing Comparison](https://llm-price.com/)

---

*Document gÃ©nÃ©rÃ© le 17 janvier 2026*
*BasÃ© sur l'analyse de l'architecture actuelle et la recherche des meilleures pratiques 2024-2026*
