# Backend TODO

## Configuration AI Text Provider (G√©n√©ration de texte)

### Pour activer le provider Cerebras:

1. **Ajouter la cl√© API Cerebras dans votre fichier .env:**
   ```
   CEREBRAS_API_KEY=votre-cl√©-cerebras-ici
   ```

2. **Changer le provider AI dans .env:**
   ```
   AI_PROVIDER=cerebras
   ```

3. **Red√©marrer le serveur:**
   ```
   npm run dev
   ```

### Switching entre text providers:

- **Pour utiliser Grok (d√©faut):**
  ```
  AI_PROVIDER=grok
  ```

- **Pour utiliser Cerebras:**
  ```
  AI_PROVIDER=cerebras
  ```

### Models utilis√©s (Text):

- **Grok:** `grok-4-1-fast`
- **Cerebras:** `gpt-oss-120b`

---

## Configuration Speech-to-Text Provider (Transcription)

### Pour activer Groq Whisper v3 Turbo (RECOMMAND√â):

1. **Ajouter la cl√© API Groq dans votre fichier .env:**
   ```
   GROQ_API_KEY=votre-cl√©-groq-ici
   ```

2. **Changer le provider STT dans .env:**
   ```
   STT_PROVIDER=groq-whisper-v3-turbo
   ```

3. **Red√©marrer le serveur:**
   ```
   npm run dev
   ```

### Switching entre STT providers:

- **Pour utiliser Deepgram Nova-3 (d√©faut):**
  ```
  STT_PROVIDER=deepgram
  ```

- **Pour utiliser Groq Whisper Large v3:**
  ```
  STT_PROVIDER=groq-whisper-v3
  ```

- **Pour utiliser Groq Whisper v3 Turbo (recommand√© - 8x plus rapide):**
  ```
  STT_PROVIDER=groq-whisper-v3-turbo
  ```

### Models utilis√©s (Speech-to-Text):

- **Deepgram:** `nova-3` (rapide, fiable)
- **Groq Whisper v3:** `whisper-large-v3` (pr√©cision maximale)
- **Groq Whisper v3 Turbo:** `whisper-large-v3-turbo` (meilleur √©quilibre vitesse/pr√©cision)

### Comparaison des providers STT:

| Provider | Vitesse | Pr√©cision | Co√ªt | Recommand√© pour |
|----------|---------|-----------|------|-----------------|
| Deepgram Nova-3 | ‚ö°‚ö°‚ö° Tr√®s rapide | ‚≠ê‚≠ê‚≠ê Excellente | üí∞üí∞ Moyen | Production stable |
| Groq Whisper v3 | ‚ö°‚ö° Rapide | ‚≠ê‚≠ê‚≠ê‚≠ê Maximale | üí∞ √âconomique | Pr√©cision maximale |
| Groq Whisper v3 Turbo | ‚ö°‚ö°‚ö°‚ö° Ultra rapide | ‚≠ê‚≠ê‚≠ê Excellente | üí∞ √âconomique | **Usage g√©n√©ral** ‚úÖ |

### Notes:

- Le syst√®me switche automatiquement entre providers selon les variables d'environnement
- Si `AI_PROVIDER` n'est pas d√©fini, le syst√®me utilise Grok par d√©faut
- Si `STT_PROVIDER` n'est pas d√©fini, le syst√®me utilise Deepgram par d√©faut
- Les providers text utilisent le Vercel AI SDK
- Groq Whisper est g√©n√©ralement plus rapide et moins cher que Deepgram
- Tous les appels AI text sont centralis√©s dans `/backend/src/lib/ai-provider.ts`
- Tous les appels STT sont centralis√©s dans `/backend/src/lib/speech-to-text-provider.ts`
